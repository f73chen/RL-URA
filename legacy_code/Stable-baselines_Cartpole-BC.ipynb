{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines.common import set_global_seeds\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.gail import generate_expert_traj, ExpertDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "expert_path = \"tmp/gym/CartPole/behaviour_cloning/expert_model.zip\"\n",
    "save_path = \"tmp/gym/CartPole/behaviour_cloning/expert_model_traj.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectory already exists. Extraction will not be performed\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(save_path) is False:\n",
    "    env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "    env.max_episode_steps = 500\n",
    "    model = PPO2.load(expert_path, env=env)\n",
    "    generate_expert_traj(model, save_path=save_path, env=env, n_episodes=1000)\n",
    "else:\n",
    "    print('trajectory already exists. Extraction will not be performed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (498858, 1)\n",
      "obs (498858, 4)\n",
      "rewards (498858, 1)\n",
      "episode_returns (1000,)\n",
      "episode_starts (498858,)\n",
      "Total trajectories: -1\n",
      "Total transitions: 498858\n",
      "Average returns: 498.858\n",
      "Std for returns: 18.93720771391601\n"
     ]
    }
   ],
   "source": [
    "dataset = ExpertDataset(expert_path=save_path, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean_reward, n_steps = -np.inf, 0\n",
    "\n",
    "def callback(_locals, _globals):\n",
    "    \"\"\"\n",
    "    Callback called at each step (for DQN an others) or after n steps (see ACER or PPO2)\n",
    "    :param _locals: (dict)\n",
    "    :param _globals: (dict)\n",
    "    \"\"\"\n",
    "    global n_steps, best_mean_reward\n",
    "    # Print stats every 1000 calls\n",
    "    if (n_steps + 1) % 10 == 0:\n",
    "        # Evaluate policy training performance\n",
    "        x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "        if len(x) > 0:\n",
    "            mean_reward = np.mean(y[-100:])\n",
    "            print(x[-1], 'timesteps')\n",
    "            print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(best_mean_reward, mean_reward))\n",
    "\n",
    "            # New best model, you could save the agent here\n",
    "            if mean_reward > best_mean_reward:\n",
    "                best_mean_reward = mean_reward\n",
    "                # Example for saving best model\n",
    "                print(\"Saving new best model\")\n",
    "                _locals['self'].save(log_dir + 'best_model.pkl')\n",
    "    n_steps += 1\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "env = gym.make(env_id)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining with Behavior Cloning...\n",
      "==== Training progress 1.00% ====\n",
      "Epoch 1\n",
      "Training loss: 0.552960, Validation loss: 0.526862\n",
      "\n",
      "==== Training progress 2.00% ====\n",
      "Epoch 2\n",
      "Training loss: 0.522406, Validation loss: 0.518123\n",
      "\n",
      "==== Training progress 3.00% ====\n",
      "Epoch 3\n",
      "Training loss: 0.519236, Validation loss: 0.517809\n",
      "\n",
      "==== Training progress 4.00% ====\n",
      "Epoch 4\n",
      "Training loss: 0.519103, Validation loss: 0.517788\n",
      "\n",
      "==== Training progress 5.00% ====\n",
      "Epoch 5\n",
      "Training loss: 0.519108, Validation loss: 0.517702\n",
      "\n",
      "==== Training progress 6.00% ====\n",
      "Epoch 6\n",
      "Training loss: 0.519120, Validation loss: 0.517585\n",
      "\n",
      "==== Training progress 7.00% ====\n",
      "Epoch 7\n",
      "Training loss: 0.519264, Validation loss: 0.517529\n",
      "\n",
      "==== Training progress 8.00% ====\n",
      "Epoch 8\n",
      "Training loss: 0.519108, Validation loss: 0.517818\n",
      "\n",
      "==== Training progress 9.00% ====\n",
      "Epoch 9\n",
      "Training loss: 0.519132, Validation loss: 0.517596\n",
      "\n",
      "==== Training progress 10.00% ====\n",
      "Epoch 10\n",
      "Training loss: 0.519204, Validation loss: 0.517634\n",
      "\n",
      "==== Training progress 11.00% ====\n",
      "Epoch 11\n",
      "Training loss: 0.519074, Validation loss: 0.517531\n",
      "\n",
      "==== Training progress 12.00% ====\n",
      "Epoch 12\n",
      "Training loss: 0.519114, Validation loss: 0.517729\n",
      "\n",
      "==== Training progress 13.00% ====\n",
      "Epoch 13\n",
      "Training loss: 0.519204, Validation loss: 0.517678\n",
      "\n",
      "==== Training progress 14.00% ====\n",
      "Epoch 14\n",
      "Training loss: 0.519156, Validation loss: 0.517670\n",
      "\n",
      "==== Training progress 15.00% ====\n",
      "Epoch 15\n",
      "Training loss: 0.519123, Validation loss: 0.517694\n",
      "\n",
      "==== Training progress 16.00% ====\n",
      "Epoch 16\n",
      "Training loss: 0.519164, Validation loss: 0.517677\n",
      "\n",
      "==== Training progress 17.00% ====\n",
      "Epoch 17\n",
      "Training loss: 0.519199, Validation loss: 0.517747\n",
      "\n",
      "==== Training progress 18.00% ====\n",
      "Epoch 18\n",
      "Training loss: 0.519077, Validation loss: 0.517897\n",
      "\n",
      "==== Training progress 19.00% ====\n",
      "Epoch 19\n",
      "Training loss: 0.519105, Validation loss: 0.518016\n",
      "\n",
      "==== Training progress 20.00% ====\n",
      "Epoch 20\n",
      "Training loss: 0.519064, Validation loss: 0.517435\n",
      "\n",
      "==== Training progress 21.00% ====\n",
      "Epoch 21\n",
      "Training loss: 0.519118, Validation loss: 0.517967\n",
      "\n",
      "==== Training progress 22.00% ====\n",
      "Epoch 22\n",
      "Training loss: 0.519171, Validation loss: 0.517627\n",
      "\n",
      "==== Training progress 23.00% ====\n",
      "Epoch 23\n",
      "Training loss: 0.519175, Validation loss: 0.517600\n",
      "\n",
      "==== Training progress 24.00% ====\n",
      "Epoch 24\n",
      "Training loss: 0.519146, Validation loss: 0.517765\n",
      "\n",
      "==== Training progress 25.00% ====\n",
      "Epoch 25\n",
      "Training loss: 0.519154, Validation loss: 0.517571\n",
      "\n",
      "==== Training progress 26.00% ====\n",
      "Epoch 26\n",
      "Training loss: 0.519082, Validation loss: 0.517726\n",
      "\n",
      "==== Training progress 27.00% ====\n",
      "Epoch 27\n",
      "Training loss: 0.519107, Validation loss: 0.517879\n",
      "\n",
      "==== Training progress 28.00% ====\n",
      "Epoch 28\n",
      "Training loss: 0.519177, Validation loss: 0.517700\n",
      "\n",
      "==== Training progress 29.00% ====\n",
      "Epoch 29\n",
      "Training loss: 0.519103, Validation loss: 0.517672\n",
      "\n",
      "==== Training progress 30.00% ====\n",
      "Epoch 30\n",
      "Training loss: 0.519088, Validation loss: 0.517482\n",
      "\n",
      "==== Training progress 31.00% ====\n",
      "Epoch 31\n",
      "Training loss: 0.519139, Validation loss: 0.517677\n",
      "\n",
      "==== Training progress 32.00% ====\n",
      "Epoch 32\n",
      "Training loss: 0.519120, Validation loss: 0.517585\n",
      "\n",
      "==== Training progress 33.00% ====\n",
      "Epoch 33\n",
      "Training loss: 0.519197, Validation loss: 0.517836\n",
      "\n",
      "==== Training progress 34.00% ====\n",
      "Epoch 34\n",
      "Training loss: 0.519114, Validation loss: 0.517620\n",
      "\n",
      "==== Training progress 35.00% ====\n",
      "Epoch 35\n",
      "Training loss: 0.519164, Validation loss: 0.517918\n",
      "\n",
      "==== Training progress 36.00% ====\n",
      "Epoch 36\n",
      "Training loss: 0.519143, Validation loss: 0.517612\n",
      "\n",
      "==== Training progress 37.00% ====\n",
      "Epoch 37\n",
      "Training loss: 0.519115, Validation loss: 0.517645\n",
      "\n",
      "==== Training progress 38.00% ====\n",
      "Epoch 38\n",
      "Training loss: 0.519079, Validation loss: 0.517529\n",
      "\n",
      "==== Training progress 39.00% ====\n",
      "Epoch 39\n",
      "Training loss: 0.519111, Validation loss: 0.517669\n",
      "\n",
      "==== Training progress 40.00% ====\n",
      "Epoch 40\n",
      "Training loss: 0.519172, Validation loss: 0.517689\n",
      "\n",
      "==== Training progress 41.00% ====\n",
      "Epoch 41\n",
      "Training loss: 0.519063, Validation loss: 0.517620\n",
      "\n",
      "==== Training progress 42.00% ====\n",
      "Epoch 42\n",
      "Training loss: 0.519116, Validation loss: 0.517629\n",
      "\n",
      "==== Training progress 43.00% ====\n",
      "Epoch 43\n",
      "Training loss: 0.519119, Validation loss: 0.517658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/stable_baselines/gail/dataset/dataset.py\", line 290, in _run\n",
      "    self.queue.put((obs, actions))\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/stable_baselines/gail/dataset/dataset.py\", line 290, in _run\n",
      "    self.queue.put((obs, actions))\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "  File \"/Users/jiachengweng/opt/anaconda3/envs/stable-baselines/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c15977d30453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMlpPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/stable_baselines/common/base_class.py\u001b[0m in \u001b[0;36mpretrain\u001b[0;34m(self, dataset, n_epochs, learning_rate, adam_epsilon, val_interval)\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mactions_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexpert_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 }\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mtrain_loss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_loss_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/stable-baselines/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PPO2(MlpPolicy, env, verbose=1)\n",
    "model.pretrain(dataset, n_epochs=100, val_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrain Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for i in range(2000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
