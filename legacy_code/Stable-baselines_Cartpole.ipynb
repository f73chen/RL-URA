{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable-baselines\n",
    "\n",
    "Stable-baselines is a fork of the original baselines from OpenAI. It has many state-of-the-art reinforcement learning (RL) algorithms like the original baseline does, and provides further support such as Ipython Notebook and algorithm customization. To install Stable-baselines, please follow the instructions in the link below for `Detailed documentation`. Unix based system (Mac OS or Linux) is recommended since it makes the installation of many packages a lot easier.\n",
    "\n",
    "- Detailed documentation: https://stable-baselines.readthedocs.io/en/master/index.html\n",
    "- Github Reop: https://github.com/hill-a/stable-baselines\n",
    "\n",
    "#### Great Info about baselines\n",
    "- OpenAI Spinning Up: https://spinningup.openai.com/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "The following code is a simple example of training CartPole agent using PPO agent. It covers basic functionalities such as define, evaluate, train, save & load models.\n",
    "\n",
    "- gym can be installed using `pip install gym` in terminals for the Anaconda environment.\n",
    "    - Intro to OpenAI Gym: https://gym.openai.com/docs/\n",
    "    - look up environment ID: https://github.com/openai/gym/blob/master/gym/envs/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j5weng\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\j5weng\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\j5weng\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\j5weng\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\j5weng\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\j5weng\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines.common import set_global_seeds\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')     # Make the environement by specifying the environment ID\n",
    "env.max_episode_steps = 500       # Modeify the max episode steps to a customed value (default = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a helper function to evalute the mean reward of the last n episodes\n",
    "def evaluate(model, num_steps=1000, num_episodes=10):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_steps: (int) number of timesteps to evaluate it\n",
    "    :num_episodes: (int) number of last episodes to evaluate the results\n",
    "    :return: (float) Mean reward for the last 100 episodes\n",
    "    \"\"\"\n",
    "    episode_rewards = [0.0]\n",
    "    obs = env.reset() # reset the environment states to initial values\n",
    "    for i in range(num_steps):\n",
    "        action, _states = model.predict(obs) # _states are only useful when using LSTM policies\n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "        # Stats\n",
    "        episode_rewards[-1] += reward # accumulate the reward\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            episode_rewards.append(0.0) # add a new item into the list for a new episode\n",
    "    # Compute mean reward for the last 100 episodes\n",
    "    mean_100ep_reward = round(np.mean(episode_rewards[-num_episodes:]), 1)\n",
    "    print(\"Mean reward for the last {} episodes:\".format(num_episodes), mean_100ep_reward, \"   Num episodes:\", len(episode_rewards))\n",
    "\n",
    "    return mean_100ep_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moniter the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean_reward, n_steps = -np.inf, 0\n",
    "\n",
    "def callback(_locals, _globals):\n",
    "    \"\"\"\n",
    "    Callback called at each step (for DQN an others) or after n steps (see ACER or PPO2)\n",
    "    :param _locals: (dict)\n",
    "    :param _globals: (dict)\n",
    "    \"\"\"\n",
    "    global n_steps, best_mean_reward\n",
    "    # Print stats every 1000 calls\n",
    "    if (n_steps + 1) % 10 == 0:\n",
    "        # Evaluate policy training performance\n",
    "        x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "        if len(x) > 0:\n",
    "            mean_reward = np.mean(y[-10:])\n",
    "            clear_output(wait=True)\n",
    "            print(x[-1], 'timesteps')\n",
    "            print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(best_mean_reward, mean_reward))\n",
    "\n",
    "            # New best model, you could save the agent here\n",
    "            if mean_reward > best_mean_reward:\n",
    "                best_mean_reward = mean_reward\n",
    "                # Example for saving best model\n",
    "                print(\"Saving new best model\")\n",
    "                _locals['self'].save(log_dir + 'best_model.pkl')\n",
    "    n_steps += 1\n",
    "    return True\n",
    "\n",
    "\n",
    "# Create log dir\n",
    "log_dir = \"tmp/gym/CartPole/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])  # The algorithms require a vectorized environment to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e5ffc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e5ffc88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e5ffc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e5ffc88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e9dbf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e9dbf60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e9dbf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1c4e9dbf60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jiachengweng/opt/anaconda3/envs/pybullet/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PPO2(MlpPolicy, env, verbose=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################commented because it interferes with the loging function in callback\n",
    "# print('Before training:')\n",
    "# mean_reward_before_train = evaluate(model, num_steps=10000, num_episodes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=200000, callback=callback)\n",
    "model.save(log_dir+'latest_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################commented because it interferes with the loging function in callback\n",
    "# print('After training:')\n",
    "# mean_reward_before_train = evaluate(model, num_steps=10000, num_episodes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(values, window):\n",
    "    \"\"\"\n",
    "    Smooth values by doing a moving average\n",
    "    :param values: (numpy array)\n",
    "    :param window: (int)\n",
    "    :return: (numpy array)\n",
    "    \"\"\"\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, 'valid')\n",
    "\n",
    "\n",
    "def plot_results(log_folder, title='Learning Curve'):\n",
    "    \"\"\"\n",
    "    plot the results\n",
    "\n",
    "    :param log_folder: (str) the save location of the results to plot\n",
    "    :param title: (str) the title of the task to plot\n",
    "    \"\"\"\n",
    "    x, y = ts2xy(load_results(log_folder), 'timesteps')\n",
    "    y = moving_average(y, window=10)\n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y):]\n",
    "\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Number of Timesteps')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.title(title + \" Smoothed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for i in range(2000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [NOTE ONLY] Save & load the model entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the agent as a .pkl file\n",
    "model.save(\"PPO2_CartPole\") \n",
    "\n",
    "# delete & load the model (recrete the model entirely)\n",
    "del model\n",
    "model = PPO2.load('PPO2_CartPole')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [NOTE ONLY] Save & load the model parameters only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameters from a saved model to a defined model\n",
    "model.load_parameters(log_dir+'best_model.pkl', exact_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing\n",
    "\n",
    "Multiprocessing allows us to run multiple environments at the same time. To multiprocess RL training, we will just have to wrap the Gym env into a SubprocVecEnv object, that will take care of synchronising the processes.\n",
    "\n",
    "- an additional utility function `make_env` is needed to instantiate the environments\n",
    "- `make_env` uses different seeds to ensure each env is different\n",
    "- vectorized environment is required: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_id, rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    \n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environment you wish to have in subprocesses \n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    set_global_seeds(seed)\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, num_steps=1000, visualize=False):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_steps: (int) number of timesteps to evaluate it\n",
    "    :return: (float) Mean reward\n",
    "    \"\"\"\n",
    "    episode_rewards = [[0.0] for _ in range(env.num_envs)]\n",
    "    obs = env.reset()\n",
    "    for i in range(num_steps):\n",
    "        # _states are only useful when using LSTM policies\n",
    "        actions, _states = model.predict(obs)\n",
    "        # here, action, rewards and dones are arrays\n",
    "        # because we are using vectorized env\n",
    "        obs, rewards, dones, info = env.step(actions)\n",
    "        if visualize:\n",
    "            env.render(mode='rgb_array')\n",
    "\n",
    "        # Stats\n",
    "        for i in range(env.num_envs):\n",
    "            episode_rewards[i][-1] += rewards[i]\n",
    "            if dones[i]:\n",
    "                episode_rewards[i].append(0.0)\n",
    "\n",
    "    mean_rewards =  [0.0 for _ in range(env.num_envs)]\n",
    "    n_episodes = 0\n",
    "    for i in range(env.num_envs):\n",
    "        mean_rewards[i] = np.mean(episode_rewards[i])     \n",
    "        n_episodes += len(episode_rewards[i])   \n",
    "\n",
    "    # Compute mean reward\n",
    "    mean_reward = round(np.mean(mean_rewards), 1)\n",
    "    print(\"Mean reward:\", mean_reward, \"Num episodes:\", n_episodes)\n",
    "\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "num_cpu = 11  # Number of processes to use\n",
    "# Create the vectorized environment\n",
    "env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 21.0 Num episodes: 526\n"
     ]
    }
   ],
   "source": [
    "mean_reward_before_train = evaluate(model, num_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1ee2b6a83140>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    337\u001b[0m                 \u001b[0mcliprange_vf_now\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcliprange_vf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[1;31m# true_reward is the reward without discount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneglogpacs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep_infos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mep_info_buf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mep_infos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\stable_baselines\\ppo2\\ppo2.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[0mmaybe_ep_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'episode'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\stable_baselines\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \"\"\"\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\site-packages\\stable_baselines\\common\\vec_env\\subproc_vec_env.py\u001b[0m in \u001b[0;36mstep_async\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mremote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaiting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opensim-rl\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[1;34m(self, buf)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_send_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWriteFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverlapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mERROR_IO_PENDING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 204.2 Num episodes: 20\n"
     ]
    }
   ],
   "source": [
    "mean_reward_after_train = evaluate(model, num_steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the benefit of using `SubprocVecEnv` is not as beneficial for simple environment because the overhead of multiprocessing outweights the environment computational time: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
